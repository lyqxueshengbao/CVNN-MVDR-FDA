"""
æ”¹è¿›ç‰ˆæ··åˆé¢„çƒ­å¯åŠ¨å®éªŒï¼šDCVBåˆå§‹åŒ– + å¿«é€Ÿå¾®è°ƒ
éªŒè¯æ·±åº¦ç½‘ç»œæƒå€¼ä½œä¸ºä¼ ç»Ÿç®—æ³•åˆå§‹å€¼çš„æœ‰æ•ˆæ€§
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from config import Config
from data_gen_v2 import FdaMimoSimulatorV2
from model import ComplexBeamformerNet
import time

plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False


def apply_mvdr_constraint(w, a_target):
    """å•æ­¥MVDRçº¦æŸæŠ•å½±ï¼ˆå¿«é€Ÿå¾®è°ƒï¼‰"""
    inner_prod = torch.sum(w.conj() * a_target, dim=-1, keepdim=True)
    norm_a_sq = torch.sum(a_target.conj() * a_target, dim=-1, keepdim=True)
    correction = a_target * (inner_prod.conj() - 1.0) / (norm_a_sq + 1e-8)
    return w - correction


def power_iteration_refine(R, a_target, w_init, n_iters=5):
    """
    ä» w_init å¼€å§‹ï¼Œä½¿ç”¨å…±è½­æ¢¯åº¦æ³•å¿«é€Ÿå¾®è°ƒ
    æ¯æ¬¡è¿­ä»£ï¼šw â† w - Î±*(R*w), ç„¶åæŠ•å½±åˆ°çº¦æŸæµå½¢
    """
    w = w_init.clone()
    power_history = []
    
    for it in range(n_iters):
        # è®¡ç®—å½“å‰åŠŸç‡
        P = torch.real(w.conj() @ R @ w).item()
        power_history.append(P)
        
        # æ¢¯åº¦ä¸‹é™ï¼šæœ€å°åŒ– w^H * R * w
        grad = R @ w
        
        # è‡ªé€‚åº”æ­¥é•¿ï¼ˆåŸºäºå½“å‰åŠŸç‡ï¼‰
        alpha = 0.5 / (torch.norm(grad).item() + 1e-8)
        
        # æ›´æ–°æƒå€¼
        w_new = w - alpha * grad
        
        # æŠ•å½±åˆ° MVDR çº¦æŸæµå½¢ï¼šw^H * a = 1
        w = apply_mvdr_constraint(w_new, a_target)
    
    # æœ€åè®¡ç®—ä¸€æ¬¡åŠŸç‡
    P_final = torch.real(w.conj() @ R @ w).item()
    power_history.append(P_final)
    
    return w, np.array(power_history)


def compare_hybrid_methods():
    """
    å¯¹æ¯”å››ç§æ–¹æ³•ï¼š
    1. çº¯ DCVBï¼ˆå¿«é€Ÿä½†ç²¾åº¦æœ‰é™ï¼‰
    2. DCVB + 3æ¬¡è¿­ä»£å¾®è°ƒï¼ˆæ··åˆæ–¹æ³•ï¼‰
    3. DCVB + 10æ¬¡è¿­ä»£å¾®è°ƒï¼ˆæ··åˆæ–¹æ³•ï¼Œæ›´ç²¾ç»†ï¼‰
    4. ç›´æ¥ MVDRï¼ˆæœ€ä¼˜ä½†æ…¢ï¼‰
    """
    cfg = Config()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}\n")
    
    # åŠ è½½ DCVB æ¨¡å‹
    model = ComplexBeamformerNet(cfg=cfg).to(device)
    model.load_state_dict(torch.load('fda_improved.pth', map_location=device, weights_only=False))
    model.eval()
    
    # é¢„çƒ­CUDAï¼ˆå…³é”®ï¼ï¼‰
    print("=== CUDA é¢„çƒ­ ===")
    simulator = FdaMimoSimulatorV2(cfg)
    for _ in range(3):
        X_warm, a_warm = simulator.generate_batch(range_diff_mode='fixed')
        with torch.no_grad():
            _ = model(X_warm, a_warm)
    print("é¢„çƒ­å®Œæˆ\n")
    
    # ç”Ÿæˆ100ä¸ªæµ‹è¯•æ ·æœ¬ï¼Œå–å¹³å‡
    num_tests = 50
    times_dcvb = []
    times_hybrid_3 = []
    times_hybrid_10 = []
    times_mvdr = []
    
    perfs_dcvb = []
    perfs_hybrid_3 = []
    perfs_hybrid_10 = []
    perfs_mvdr = []
    
    print("å¼€å§‹æµ‹è¯•ï¼ˆ50ä¸ªæ ·æœ¬ï¼‰...")
    for idx in range(num_tests):
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        X, a_tgt = simulator.generate_batch(range_diff_mode='random')
        
        # è®¡ç®—åæ–¹å·®çŸ©é˜µ
        with torch.no_grad():
            R = torch.matmul(X, X.conj().transpose(-1, -2)) / cfg.L
            R = R[0]  # (MN, MN)
            a_tgt_vec = a_tgt[0]  # (MN,)
        
        # ===== æ–¹æ³•1ï¼šçº¯ DCVB =====
        torch.cuda.synchronize() if device.type == 'cuda' else None
        t0 = time.time()
        with torch.no_grad():
            w_dcvb = model(X, a_tgt)[0]
        torch.cuda.synchronize() if device.type == 'cuda' else None
        t_dcvb = time.time() - t0
        
        P_dcvb = torch.real(w_dcvb.conj() @ R @ w_dcvb).item()
        times_dcvb.append(t_dcvb)
        perfs_dcvb.append(10 * np.log10(P_dcvb))
        
        # ===== æ–¹æ³•2ï¼šDCVB + 3æ¬¡è¿­ä»£ =====
        t0 = time.time()
        w_hybrid_3, power_hist_3 = power_iteration_refine(R, a_tgt_vec, w_dcvb, n_iters=3)
        t_refine_3 = time.time() - t0
        
        times_hybrid_3.append(t_dcvb + t_refine_3)
        perfs_hybrid_3.append(10 * np.log10(power_hist_3[-1]))
        
        # ===== æ–¹æ³•3ï¼šDCVB + 10æ¬¡è¿­ä»£ =====
        t0 = time.time()
        w_hybrid_10, power_hist_10 = power_iteration_refine(R, a_tgt_vec, w_dcvb, n_iters=10)
        t_refine_10 = time.time() - t0
        
        times_hybrid_10.append(t_dcvb + t_refine_10)
        perfs_hybrid_10.append(10 * np.log10(power_hist_10[-1]))
        
        # ===== æ–¹æ³•4ï¼šç›´æ¥ MVDR =====
        t0 = time.time()
        MN = cfg.M * cfg.N
        R_inv = torch.linalg.inv(R + 1e-6 * torch.eye(MN, device=device))
        numerator = R_inv @ a_tgt_vec
        denominator = a_tgt_vec.conj() @ R_inv @ a_tgt_vec
        w_mvdr = numerator / denominator
        t_mvdr = time.time() - t0
        
        P_mvdr = torch.real(w_mvdr.conj() @ R @ w_mvdr).item()
        times_mvdr.append(t_mvdr)
        perfs_mvdr.append(10 * np.log10(P_mvdr))
        
        if (idx + 1) % 10 == 0:
            print(f"  å·²å®Œæˆ {idx+1}/{num_tests}")
    
    # è®¡ç®—ç»Ÿè®¡é‡
    def stats(arr):
        return np.mean(arr), np.std(arr)
    
    print("\n" + "="*70)
    print("å®éªŒç»“æœç»Ÿè®¡ï¼ˆ50ä¸ªæ ·æœ¬å¹³å‡ï¼‰")
    print("="*70)
    
    t_dcvb_avg, t_dcvb_std = stats([t*1000 for t in times_dcvb])
    t_h3_avg, t_h3_std = stats([t*1000 for t in times_hybrid_3])
    t_h10_avg, t_h10_std = stats([t*1000 for t in times_hybrid_10])
    t_mvdr_avg, t_mvdr_std = stats([t*1000 for t in times_mvdr])
    
    p_dcvb_avg, p_dcvb_std = stats(perfs_dcvb)
    p_h3_avg, p_h3_std = stats(perfs_hybrid_3)
    p_h10_avg, p_h10_std = stats(perfs_hybrid_10)
    p_mvdr_avg, p_mvdr_std = stats(perfs_mvdr)
    
    print("\nã€æ–¹æ³•1ã€‘çº¯ DCVBï¼ˆæ— å¾®è°ƒï¼‰")
    print(f"  æ—¶é—´: {t_dcvb_avg:.2f} Â± {t_dcvb_std:.2f} ms")
    print(f"  æŠ‘åˆ¶: {p_dcvb_avg:.2f} Â± {p_dcvb_std:.2f} dB")
    
    print("\nã€æ–¹æ³•2ã€‘æ··åˆæ–¹æ³•ï¼ˆDCVB + 3æ¬¡å¾®è°ƒï¼‰")
    print(f"  æ—¶é—´: {t_h3_avg:.2f} Â± {t_h3_std:.2f} ms")
    print(f"  æŠ‘åˆ¶: {p_h3_avg:.2f} Â± {p_h3_std:.2f} dB")
    print(f"  ç›¸æ¯”çº¯DCVBæ”¹è¿›: {p_h3_avg - p_dcvb_avg:.2f} dB")
    print(f"  é€Ÿåº¦ä¼˜åŠ¿ vs MVDR: {t_mvdr_avg / t_h3_avg:.1f}Ã— æ›´å¿«")
    
    print("\nã€æ–¹æ³•3ã€‘æ··åˆæ–¹æ³•ï¼ˆDCVB + 10æ¬¡å¾®è°ƒï¼‰")
    print(f"  æ—¶é—´: {t_h10_avg:.2f} Â± {t_h10_std:.2f} ms")
    print(f"  æŠ‘åˆ¶: {p_h10_avg:.2f} Â± {p_h10_std:.2f} dB")
    print(f"  ç›¸æ¯”çº¯DCVBæ”¹è¿›: {p_h10_avg - p_dcvb_avg:.2f} dB")
    print(f"  é€Ÿåº¦ä¼˜åŠ¿ vs MVDR: {t_mvdr_avg / t_h10_avg:.1f}Ã— æ›´å¿«")
    
    print("\nã€æ–¹æ³•4ã€‘ç›´æ¥ MVDRï¼ˆé—­å¼è§£ï¼Œæœ€ä¼˜åŸºå‡†ï¼‰")
    print(f"  æ—¶é—´: {t_mvdr_avg:.2f} Â± {t_mvdr_std:.2f} ms")
    print(f"  æŠ‘åˆ¶: {p_mvdr_avg:.2f} Â± {p_mvdr_std:.2f} dB")
    
    # å¯è§†åŒ–
    fig = plt.figure(figsize=(16, 5))
    
    # å­å›¾1ï¼šæ€§èƒ½å¯¹æ¯”ï¼ˆç®±çº¿å›¾ï¼‰
    ax1 = plt.subplot(1, 3, 1)
    positions = [1, 2, 3, 4]
    data = [perfs_dcvb, perfs_hybrid_3, perfs_hybrid_10, perfs_mvdr]
    bp = ax1.boxplot(data, positions=positions, widths=0.6, patch_artist=True,
                     boxprops=dict(facecolor='lightblue', alpha=0.7),
                     medianprops=dict(color='red', linewidth=2))
    
    ax1.set_xticks(positions)
    ax1.set_xticklabels(['çº¯DCVB', 'DCVB+3æ¬¡', 'DCVB+10æ¬¡', 'MVDR'], fontsize=11)
    ax1.set_ylabel('å¹²æ‰°æŠ‘åˆ¶ (dB)', fontsize=12)
    ax1.set_title('(a) æŠ‘åˆ¶æ·±åº¦å¯¹æ¯”ï¼ˆ50æ ·æœ¬ï¼‰', fontsize=13, fontweight='bold')
    ax1.grid(True, axis='y', alpha=0.3)
    ax1.axhline(y=p_mvdr_avg, color='green', linestyle='--', linewidth=1.5, alpha=0.7, label='MVDRå¹³å‡')
    ax1.legend(fontsize=10)
    
    # å­å›¾2ï¼šæ—¶é—´å¯¹æ¯”ï¼ˆç®±çº¿å›¾ï¼‰
    ax2 = plt.subplot(1, 3, 2)
    time_data = [[t*1000 for t in times_dcvb], 
                 [t*1000 for t in times_hybrid_3], 
                 [t*1000 for t in times_hybrid_10], 
                 [t*1000 for t in times_mvdr]]
    bp2 = ax2.boxplot(time_data, positions=positions, widths=0.6, patch_artist=True,
                      boxprops=dict(facecolor='lightcoral', alpha=0.7),
                      medianprops=dict(color='darkred', linewidth=2))
    
    ax2.set_xticks(positions)
    ax2.set_xticklabels(['çº¯DCVB', 'DCVB+3æ¬¡', 'DCVB+10æ¬¡', 'MVDR'], fontsize=11)
    ax2.set_ylabel('è®¡ç®—æ—¶é—´ (ms)', fontsize=12)
    ax2.set_title('(b) è®¡ç®—æ—¶é—´å¯¹æ¯”ï¼ˆ50æ ·æœ¬ï¼‰', fontsize=13, fontweight='bold')
    ax2.set_yscale('log')
    ax2.grid(True, axis='y', alpha=0.3, which='both')
    
    # å­å›¾3ï¼šæ€§èƒ½-æ—¶é—´æƒè¡¡ï¼ˆæ•£ç‚¹å›¾ï¼‰
    ax3 = plt.subplot(1, 3, 3)
    
    # ç»˜åˆ¶æ‰€æœ‰æ ·æœ¬
    ax3.scatter([t*1000 for t in times_dcvb], perfs_dcvb, alpha=0.3, s=30, c='orange', label='çº¯DCVB')
    ax3.scatter([t*1000 for t in times_hybrid_3], perfs_hybrid_3, alpha=0.3, s=30, c='blue', label='DCVB+3æ¬¡')
    ax3.scatter([t*1000 for t in times_hybrid_10], perfs_hybrid_10, alpha=0.3, s=30, c='purple', label='DCVB+10æ¬¡')
    ax3.scatter([t*1000 for t in times_mvdr], perfs_mvdr, alpha=0.3, s=30, c='green', label='MVDR')
    
    # æ ‡æ³¨å¹³å‡å€¼
    methods = ['çº¯DCVB', 'DCVB+3æ¬¡', 'DCVB+10æ¬¡', 'MVDR']
    time_avgs = [t_dcvb_avg, t_h3_avg, t_h10_avg, t_mvdr_avg]
    perf_avgs = [p_dcvb_avg, p_h3_avg, p_h10_avg, p_mvdr_avg]
    colors = ['orange', 'blue', 'purple', 'green']
    markers = ['o', '^', 's', 'D']
    
    for method, t_avg, p_avg, color, marker in zip(methods, time_avgs, perf_avgs, colors, markers):
        ax3.scatter(t_avg, p_avg, s=300, c=color, marker=marker, 
                   edgecolors='black', linewidth=2.5, zorder=10)
        ax3.text(t_avg, p_avg + 1.5, method, ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    ax3.set_xlabel('è®¡ç®—æ—¶é—´ (ms)', fontsize=12)
    ax3.set_ylabel('å¹²æ‰°æŠ‘åˆ¶ (dB)', fontsize=12)
    ax3.set_title('(c) æ€§èƒ½-æ—¶é—´æƒè¡¡ç©ºé—´', fontsize=13, fontweight='bold')
    ax3.set_xscale('log')
    ax3.grid(True, alpha=0.3, which='both')
    ax3.legend(fontsize=9, loc='lower right')
    
    plt.tight_layout()
    plt.savefig('exp_hybrid_warmstart_v2.png', dpi=300, bbox_inches='tight')
    print("\nå›¾è¡¨å·²ä¿å­˜: exp_hybrid_warmstart_v2.png")
    
    # æ‰“å°æ··åˆæ–¹æ³•çš„å…³é”®å‘ç°
    print("\n" + "="*70)
    print("æ··åˆæ–¹æ³•çš„ä»·å€¼ä¸»å¼ ")
    print("="*70)
    
    improvement_3 = p_h3_avg - p_dcvb_avg
    speedup_3 = t_mvdr_avg / t_h3_avg
    gap_to_mvdr_3 = p_mvdr_avg - p_h3_avg
    
    print(f"\nğŸ¯ æœ€ä½³å¹³è¡¡ç‚¹ï¼šDCVB + 3æ¬¡å¾®è°ƒ")
    print(f"  âœ… ä»…éœ€ {t_h3_avg:.2f} msï¼ˆMVDRçš„ 1/{speedup_3:.1f}ï¼‰")
    print(f"  âœ… æŠ‘åˆ¶æ·±åº¦ {p_h3_avg:.2f} dBï¼ˆæ¯”çº¯DCVBæå‡ {improvement_3:.2f} dBï¼‰")
    print(f"  âœ… è·ç¦»æœ€ä¼˜è§£ä»… {abs(gap_to_mvdr_3):.2f} dB")
    print(f"\nğŸ’¡ é€‚ç”¨åœºæ™¯ï¼š")
    print(f"  - å®æ—¶è·Ÿè¸ªï¼š{1000/t_h3_avg:.0f} fps ååé‡")
    print(f"  - ç²¾åº¦è¦æ±‚ï¼šä¸­ç­‰ï¼ˆ-{abs(p_h3_avg):.1f} dB å¹²æ‰°æŠ‘åˆ¶ï¼‰")
    print(f"  - èµ„æºå—é™ï¼šæ— éœ€çŸ©é˜µæ±‚é€†ï¼ˆO(NÂ²) vs O(NÂ³)ï¼‰")


if __name__ == '__main__':
    compare_hybrid_methods()
